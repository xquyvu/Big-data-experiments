{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Streaming\n",
    "\n",
    "We start by creating a streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local StreamingContext with a batch interval of 10 second\n",
    "from pyspark.streaming import StreamingContext\n",
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a stream that reads from a network socket. This will read data that we send by hand from a terminal later.\n",
    "\n",
    "We need to specify a PORTNUMBER, which has to be unique for each socket and server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DStream that will connect to hostname:port, like localhost:19999 \n",
    "lines = ssc.socketTextStream(\"localhost\", 6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stream produces a sequence of RDDs, each RDD referred to as a batch. Therefore we can apply some RDD functionality, like flatMap or map. Finally we make it a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple # Each element will be assigned a field\n",
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  .filter( lambda word: word.lower().startswith(\"#\") ) # Checks for hashtag calls\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word, sets up a tuple\n",
    "  .reduceByKey( lambda a, b: a + b ) # Reduces by key\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # Stores in a Tweet Object\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) # Sorts in descendoing order by count\n",
    "  .limit(10).registerTempTable(\"tweets\") ) ) # For every ten tweets is will be egistered as a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up the stream, but it is not yet running. For that we need to start the StreamingContext (ssc).\n",
    "\n",
    "**Before starting the streaming context in the next cell, you need to start the server that it will read from: **\n",
    "\n",
    "1) open a terminal, just like the one you used to start the jupyter notebook, via SSH.\n",
    "\n",
    "2) for testing, use the file  `RandomRead.py`. It contains a PORTNUMBER which you need to adjust to the one used  above (3 cells before this one). You can then run the server with `python3 RandomRead.py`. \n",
    " \n",
    "3) then start the cell below, it should show arriving words like `Lorem ipsum dolor sit amet [...]`\n",
    "\n",
    "4) once that works, stope the server on the terminal with ctrl-C, and start the `TweetRead.py`. Here you will also need to adjust the PORTNUMBER. I have set up a Twitter account called \"City University Big Data Module\". Please don't post tweets on there, and if you are going run it for more than testing, please get your own credentials from [https://apps.twitter.com](https://apps.twitter.com).\n",
    "\n",
    "Watch the ouptut, if it says anything about port number taken. If you get strange behaviour try restarting and using PORTNUMBER + 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ssc.start()             # Start the computation\n",
    "# after this, the stream will still run but it won't block the notebook any more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've tested the stream processing, you can stop the stream context with the next cell. After this the stream context is not usable and more and you need to restart this notebook to start another stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display # Enables us to show stuff in the notebook\n",
    "import matplotlib.pyplot as plt #Visualization library\n",
    "import seaborn as sns # Visualization library\n",
    "# Only works for Jupyter Notebooks!\n",
    "# The following code enables us to view the bar plot within a cell in the jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will fail if there is not data actually coming in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while count < 10:\n",
    "    \n",
    "    time.sleep( 3 )\n",
    "    top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )\n",
    "    top_10_df = top_10_tweets.toPandas() # Dataframe library\n",
    "    display.clear_output(wait=True) #Clears the output, if a plot exists.\n",
    "    sns.plt.figure( figsize = ( 10, 8 ) )\n",
    "    sns.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "    sns.plt.show()\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, stop the stream. You can not restart it in the same process, therefore you have to restart the kernel to start again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
